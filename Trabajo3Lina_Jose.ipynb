{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabajo3Lina_Jose.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4gI3aMvyqY6zWdKeUPq6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmbd92/st1800-st1801-trabajo3-2261/blob/main/Trabajo3Lina_Jose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrantes: Lina Beltrán (lbeltra1@eafit.edu.co), Jose Muñoz (jjmunozm@eafit.edu.co)\n",
        "\n",
        "Materia: Alm. & Recu. de información.\n",
        "\n",
        "Trabajo 3\n",
        "\n",
        "Universidad EAFIT - Maestria ciencia en datos y analítica\n",
        "\n",
        "Trabajo 2 Unidad 2 recuperación de texto"
      ],
      "metadata": {
        "id": "Z4h_pwsBq34m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data: https://github.com/lmbd92/st1800-st1801-trabajo3-2261/blob/main/Trabajo3/twitter.txt"
      ],
      "metadata": {
        "id": "6yp5sbzv7dbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abrir archivos desde GitHub"
      ],
      "metadata": {
        "id": "UHB37enaq8xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OJO!!!! Ejecutar este bloque una sola vez (La primera vez), de lo contrario el repo se clonaría varias veces de manera recursiva\n",
        "\n",
        "!git clone -l -s https://github.com/lmbd92/st1800-st1801-trabajo3-2261.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOzWds09rd5z",
        "outputId": "b8aa33ed-c9c6-400b-cc75-46e19bec2c69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 45 (delta 19), reused 16 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (45/45), done.\n",
            "/content/cloned-repo/cloned-repo\n",
            "LICENSE    Trabajo3\t\t    twitterClimateData.csv.zip\n",
            "README.md  Trabajo3Lina_Jose.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota: Para guardar el notebook directamente en Github, dirigirse a File→Save a copy in GitHub**"
      ],
      "metadata": {
        "id": "KZbH5N-4ynB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# autenticación a github\n",
        "username = \"lmbd92\"\n",
        "!git config --global user.email '$username@gmail.com'\n",
        "!git config --global user.name '$username'\n",
        "\n",
        "password = getpass('Password:')\n",
        "\n",
        "# Agregar, hacer commit y push a cambios\n",
        "!git add .\n",
        "!git commit -m 'updating repo from colab'\n",
        "!git push origin master   "
      ],
      "metadata": {
        "id": "SKuUTR0O66FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación de ambiente de trabajo (Dependencias/librerias)"
      ],
      "metadata": {
        "id": "eNUP62YtFN2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transmisión eficiente de archivos muy grandes desde/hacia almacenamientos como S3, GCS, Azure Blob Storage, HDFS, WebHDFS\n",
        "!pip install smart-open\n",
        "\n",
        "# Modelado y procesamiento NLP\n",
        "!pip install --upgrade gensim\n",
        "!pip install nltk\n",
        "\n",
        "# Interpretar el tema en un modelo de temas que se ha ajustado a un corpus\n",
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "id": "mtsUDGc89I3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "# Soporte para expresiones regulares (RE).\n",
        "import re"
      ],
      "metadata": {
        "id": "xXpQ5d5lDgGl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk: tokenizador y stopwords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words_nltk = set(stopwords.words('english'))\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "rtPvxrfnDnXe",
        "outputId": "2999202d-90a0-4ae7-cb5b-e1c362c10b8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LYP0qN2cFAJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación de los datos"
      ],
      "metadata": {
        "id": "Lk0ARlhr5Als"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de los datos\n",
        "\n",
        "path_in = '/content/cloned-repo/Trabajo3/'\n",
        "path_out = ''\n",
        "file_name = 'twitterClimateData.csv'\n",
        "\n",
        "df= pd.read_csv(f\"{path_in}{file_name}\")\n",
        "print(df)"
      ],
      "metadata": {
        "id": "6WWOc5yXF-IE",
        "outputId": "8d7b66a6-ce80-4e60-f5f4-fe23e86e7b06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    2020                 is  \\\n",
            "0                                                 Winter                has   \n",
            "1                                                      A               year   \n",
            "2                                                  HAPPY           HOLIDAYS   \n",
            "3                                                     10          Questions   \n",
            "4                                         #climatestrike  #FridaysForFuture   \n",
            "...                                                  ...                ...   \n",
            "56287                                                 No               more   \n",
            "56288                                                 My            #Trumps   \n",
            "56289                                               Time                 is   \n",
            "56290                                               This                 is   \n",
            "56291  This assault on science is an outrage and shou...         --Phillipe   \n",
            "\n",
            "              the                   year              we      #votethemout,  \\\n",
            "0             not                stopped            this              group   \n",
            "1              of            resistance,              as              youth   \n",
            "2          #greta         #gretathunberg  #climatechange  #fridaysforfuture   \n",
            "3              to                    Ask     Politicians              About   \n",
            "4      #portraits  #uniquechristmasgifts      #shopsmall       #inspiration   \n",
            "...           ...                    ...             ...                ...   \n",
            "56287      straws                     at          LBM...               only   \n",
            "56288         may                    not         believe                 in   \n",
            "56289       over.                    Act          now!!!     #Friday4Future   \n",
            "56290          my                  first    contribution                 on   \n",
            "56291    Cousteau         #savetheplanet  #ClimateChange                NaN   \n",
            "\n",
            "                the.1          year.1  \\\n",
            "0                  of       dedicated   \n",
            "1            protests          shaped   \n",
            "2            #kickass  #climatestrike   \n",
            "3             Climate          Change   \n",
            "4               #hope  #MerryChrismas   \n",
            "...               ...             ...   \n",
            "56287              if             YOU   \n",
            "56288  #climatechange             but   \n",
            "56289  #ClimateChange  #ClimateStrike   \n",
            "56290     visualizing             the   \n",
            "56291             NaN             NaN   \n",
            "\n",
            "                                                    we.1  #climatestrike  ...  \\\n",
            "0                                                climate      activists.  ...   \n",
            "1                                                climate          change  ...   \n",
            "2                                           #chloemoretz        #climate  ...   \n",
            "3      https://www.momscleanairforce.org/ask-politici...  #climatechange  ...   \n",
            "4                                                 #LGBTQ           #LGBT  ...   \n",
            "...                                                  ...             ...  ...   \n",
            "56287                                                ask             for  ...   \n",
            "56288                                                  I            do!!  ...   \n",
            "56289                                    #Sustainability  #savetheplanet  ...   \n",
            "56290                                              facts            (now  ...   \n",
            "56291                                                NaN             NaN  ...   \n",
            "\n",
            "                matters.      2020.1            is.1     the.3   year.3  \\\n",
            "0                    NaN         NaN             NaN       NaN      NaN   \n",
            "1      #fridaysforfuture    #kickass  #climatestrike  #climate  #thwave   \n",
            "2                    NaN         NaN             NaN       NaN      NaN   \n",
            "3                    NaN         NaN             NaN       NaN      NaN   \n",
            "4                    NaN         NaN             NaN       NaN      NaN   \n",
            "...                  ...         ...             ...       ...      ...   \n",
            "56287                NaN         NaN             NaN       NaN      NaN   \n",
            "56288           #Recycle  #pollution           check        me      out   \n",
            "56289                NaN         NaN             NaN       NaN      NaN   \n",
            "56290     #savetheplanet         NaN             NaN       NaN      NaN   \n",
            "56291                NaN         NaN             NaN       NaN      NaN   \n",
            "\n",
            "                    we.3         get             shit done. (3/3)  \n",
            "0                    NaN         NaN              NaN   NaN   NaN  \n",
            "1      #chloegracemoretz       #love           #bhfyp     .   NaN  \n",
            "2                    NaN         NaN              NaN   NaN   NaN  \n",
            "3                    NaN         NaN              NaN   NaN   NaN  \n",
            "4                    NaN         NaN              NaN   NaN   NaN  \n",
            "...                  ...         ...              ...   ...   ...  \n",
            "56287                NaN         NaN              NaN   NaN   NaN  \n",
            "56288                 on  #Instagram  @flotusofficial   and  help  \n",
            "56289                NaN         NaN              NaN   NaN   NaN  \n",
            "56290                NaN         NaN              NaN   NaN   NaN  \n",
            "56291                NaN         NaN              NaN   NaN   NaN  \n",
            "\n",
            "[56292 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Características y representación"
      ],
      "metadata": {
        "id": "Cz8uJi1B5HKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis frecuencial por token o hashtags"
      ],
      "metadata": {
        "id": "Ypx9bBK_5LnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nubes de palabras por token o hashtags"
      ],
      "metadata": {
        "id": "6LWz9PDA5T7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis exploratorio no supervisado utilizando técnicas de LDA"
      ],
      "metadata": {
        "id": "yMe5YdkZ5h-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación y análisis de sentimientos"
      ],
      "metadata": {
        "id": "0BO2mYq55pvG"
      }
    }
  ]
}
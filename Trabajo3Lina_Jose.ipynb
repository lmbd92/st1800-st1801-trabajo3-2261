{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabajo3Lina_Jose.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmbd92/st1800-st1801-trabajo3-2261/blob/main/Trabajo3Lina_Jose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrantes: Lina Beltrán (lbeltra1@eafit.edu.co), Jose Muñoz (jjmunozm@eafit.edu.co)\n",
        "\n",
        "Materia: Alm. & Recu. de información.\n",
        "\n",
        "Trabajo 3\n",
        "\n",
        "Universidad EAFIT - Maestria ciencia en datos y analítica\n",
        "\n",
        "Trabajo 2 Unidad 2 recuperación de texto"
      ],
      "metadata": {
        "id": "Z4h_pwsBq34m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data: https://github.com/lmbd92/st1800-st1801-trabajo3-2261/blob/main/Trabajo3/twitter.txt"
      ],
      "metadata": {
        "id": "6yp5sbzv7dbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abrir archivos desde GitHub"
      ],
      "metadata": {
        "id": "UHB37enaq8xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OJO!!!! Ejecutar este bloque una sola vez (La primera vez), de lo contrario el repo se clonaría varias veces de manera recursiva\n",
        "\n",
        "!git clone -l -s https://github.com/lmbd92/st1800-st1801-trabajo3-2261.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOzWds09rd5z",
        "outputId": "7a820f37-25c0-4f8c-fa75-6d86bfce1d43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cloned-repo' already exists and is not an empty directory.\n",
            "/content/cloned-repo\n",
            "LICENSE    Trabajo3\t\t    twitterClimateData.csv.zip\n",
            "README.md  Trabajo3Lina_Jose.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete repo local colab (Usar solo en caso de requerir actualizar el repo desde Github Nuevamente)\n",
        "\n",
        "#!rm -r /content/cloned-repo"
      ],
      "metadata": {
        "id": "r1lCqeA9SkNA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota:** Para guardar el notebook directamente en Github, dirigirse a File→Save a copy in GitHub"
      ],
      "metadata": {
        "id": "KZbH5N-4ynB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación de ambiente de trabajo (Dependencias/librerias)"
      ],
      "metadata": {
        "id": "eNUP62YtFN2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transmisión eficiente de archivos muy grandes desde/hacia almacenamientos como S3, GCS, Azure Blob Storage, HDFS, WebHDFS\n",
        "!pip install smart-open\n",
        "\n",
        "# Modelado y procesamiento NLP\n",
        "!pip install --upgrade gensim\n",
        "!pip install nltk\n",
        "\n",
        "# Interpretar el tema en un modelo de temas que se ha ajustado a un corpus\n",
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "id": "mtsUDGc89I3Y",
        "outputId": "d1387a9b-bbf4-444f-debc-d85414e5fa1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (5.2.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (4.1.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "# Soporte para expresiones regulares (RE).\n",
        "import re"
      ],
      "metadata": {
        "id": "xXpQ5d5lDgGl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk: tokenizador y stopwords\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "stop_words_nltk = set(stopwords.words('english'))\n",
        "print(len(stopwords.words('english')))"
      ],
      "metadata": {
        "id": "rtPvxrfnDnXe",
        "outputId": "8e523f08-a547-4e25-8e36-97582d5ca2ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lematizar, Stem\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import LancasterStemmer\n",
        "#\n",
        "lancaster = LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "LYP0qN2cFAJt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimir listas grandes\n",
        "import pprint\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "c6Z6T2tpH0uy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de Data Raw y EDA básico\n",
        "\n"
      ],
      "metadata": {
        "id": "Lk0ARlhr5Als"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de los datos\n",
        "\n",
        "path_in = '/content/cloned-repo/Trabajo3/'\n",
        "path_out = '/content/cloned-repo/Trabajo3/out/'\n",
        "file_name = 'twitterClimateData.csv'\n",
        "\n",
        "df = pd.read_csv(f'{path_in}{file_name}')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6WWOc5yXF-IE",
        "outputId": "ad3628f4-4345-4d57-9eb5-fd6732f860b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0            id     author_id  \\\n",
              "0           0  1.211810e+18  7.590000e+17   \n",
              "1           1  1.210670e+18  2.219547e+07   \n",
              "2           2  1.210590e+18  1.070000e+18   \n",
              "3           3  1.210260e+18  1.339821e+09   \n",
              "4           4  1.209640e+18  1.339821e+09   \n",
              "\n",
              "                                                text  retweets  \\\n",
              "0  2020 is the year we #votethemout, the year we ...        15   \n",
              "1  Winter has not stopped this group of dedicated...         9   \n",
              "2  WEEK 55 of #ClimateStrike at the @UN. Next wee...       545   \n",
              "3   A year of resistance, as youth protests shape...         1   \n",
              "4   HAPPY HOLIDAYS #greta #gretathunberg #climate...         1   \n",
              "\n",
              "                                           permalink  \\\n",
              "0  https://twitter.com/Sphiamia/status/1211807074...   \n",
              "1  https://twitter.com/StephDujarric/status/12106...   \n",
              "2  https://twitter.com/AlexandriaV2005/status/121...   \n",
              "3  https://twitter.com/EnergyHouseVA/status/12102...   \n",
              "4  https://twitter.com/EnergyHouseVA/status/12096...   \n",
              "\n",
              "                        date                  formatted_date  favorites  \\\n",
              "0  2019-12-31 00:31:35+00:00  Tue Dec 31 00:31:35 +0000 2019         46   \n",
              "1  2019-12-27 20:56:21+00:00  Fri Dec 27 20:56:21 +0000 2019         35   \n",
              "2  2019-12-27 15:50:22+00:00  Fri Dec 27 15:50:22 +0000 2019       3283   \n",
              "3  2019-12-26 17:53:26+00:00  Thu Dec 26 17:53:26 +0000 2019          2   \n",
              "4  2019-12-25 00:56:37+00:00  Wed Dec 25 00:56:37 +0000 2019          4   \n",
              "\n",
              "              mentions  ...         location  \\\n",
              "0                  NaN  ...  California, USA   \n",
              "1                  NaN  ...  California, USA   \n",
              "2  @UN @Fridays4future  ...  California, USA   \n",
              "3                  NaN  ...  California, USA   \n",
              "4                  NaN  ...  California, USA   \n",
              "\n",
              "                                          text_clean tb_sentiment_polarity  \\\n",
              "0  2020 is the year we votethemout the year we cl...             -0.100000   \n",
              "1  Winter has not stopped this group of dedicated...              0.000000   \n",
              "2  WEEK 55 of ClimateStrike at the UN Next week F...              0.166667   \n",
              "3   A year of resistance as youth protests shaped...              0.183333   \n",
              "4   HAPPY HOLIDAYS greta gretathunberg climatecha...              0.650000   \n",
              "\n",
              "  tb_sentiment_subjectivity textBlob_sentiment vader_compound  vader_pos  \\\n",
              "0                  0.462500           negative        -0.5682      0.000   \n",
              "1                  0.000000           positive         0.5670      0.215   \n",
              "2                  0.333333           positive        -0.8567      0.023   \n",
              "3                  0.600000           positive         0.7739      0.203   \n",
              "4                  0.800000           positive         0.9413      0.451   \n",
              "\n",
              "   vader_neg vader_neu  V_Sentiment  \n",
              "0      0.131     0.869     Negative  \n",
              "1      0.000     0.785     Positive  \n",
              "2      0.180     0.797     Negative  \n",
              "3      0.051     0.746     Positive  \n",
              "4      0.000     0.549     Positive  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f482ba4-590f-4e27-8206-01c4990df580\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>text</th>\n",
              "      <th>retweets</th>\n",
              "      <th>permalink</th>\n",
              "      <th>date</th>\n",
              "      <th>formatted_date</th>\n",
              "      <th>favorites</th>\n",
              "      <th>mentions</th>\n",
              "      <th>...</th>\n",
              "      <th>location</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>tb_sentiment_polarity</th>\n",
              "      <th>tb_sentiment_subjectivity</th>\n",
              "      <th>textBlob_sentiment</th>\n",
              "      <th>vader_compound</th>\n",
              "      <th>vader_pos</th>\n",
              "      <th>vader_neg</th>\n",
              "      <th>vader_neu</th>\n",
              "      <th>V_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.211810e+18</td>\n",
              "      <td>7.590000e+17</td>\n",
              "      <td>2020 is the year we #votethemout, the year we ...</td>\n",
              "      <td>15</td>\n",
              "      <td>https://twitter.com/Sphiamia/status/1211807074...</td>\n",
              "      <td>2019-12-31 00:31:35+00:00</td>\n",
              "      <td>Tue Dec 31 00:31:35 +0000 2019</td>\n",
              "      <td>46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>California, USA</td>\n",
              "      <td>2020 is the year we votethemout the year we cl...</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>negative</td>\n",
              "      <td>-0.5682</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.131</td>\n",
              "      <td>0.869</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.210670e+18</td>\n",
              "      <td>2.219547e+07</td>\n",
              "      <td>Winter has not stopped this group of dedicated...</td>\n",
              "      <td>9</td>\n",
              "      <td>https://twitter.com/StephDujarric/status/12106...</td>\n",
              "      <td>2019-12-27 20:56:21+00:00</td>\n",
              "      <td>Fri Dec 27 20:56:21 +0000 2019</td>\n",
              "      <td>35</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>California, USA</td>\n",
              "      <td>Winter has not stopped this group of dedicated...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.5670</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.785</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.210590e+18</td>\n",
              "      <td>1.070000e+18</td>\n",
              "      <td>WEEK 55 of #ClimateStrike at the @UN. Next wee...</td>\n",
              "      <td>545</td>\n",
              "      <td>https://twitter.com/AlexandriaV2005/status/121...</td>\n",
              "      <td>2019-12-27 15:50:22+00:00</td>\n",
              "      <td>Fri Dec 27 15:50:22 +0000 2019</td>\n",
              "      <td>3283</td>\n",
              "      <td>@UN @Fridays4future</td>\n",
              "      <td>...</td>\n",
              "      <td>California, USA</td>\n",
              "      <td>WEEK 55 of ClimateStrike at the UN Next week F...</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>positive</td>\n",
              "      <td>-0.8567</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.797</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.210260e+18</td>\n",
              "      <td>1.339821e+09</td>\n",
              "      <td>A year of resistance, as youth protests shape...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://twitter.com/EnergyHouseVA/status/12102...</td>\n",
              "      <td>2019-12-26 17:53:26+00:00</td>\n",
              "      <td>Thu Dec 26 17:53:26 +0000 2019</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>California, USA</td>\n",
              "      <td>A year of resistance as youth protests shaped...</td>\n",
              "      <td>0.183333</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.7739</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.746</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.209640e+18</td>\n",
              "      <td>1.339821e+09</td>\n",
              "      <td>HAPPY HOLIDAYS #greta #gretathunberg #climate...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://twitter.com/EnergyHouseVA/status/12096...</td>\n",
              "      <td>2019-12-25 00:56:37+00:00</td>\n",
              "      <td>Wed Dec 25 00:56:37 +0000 2019</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>California, USA</td>\n",
              "      <td>HAPPY HOLIDAYS greta gretathunberg climatecha...</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.9413</td>\n",
              "      <td>0.451</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.549</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f482ba4-590f-4e27-8206-01c4990df580')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f482ba4-590f-4e27-8206-01c4990df580 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f482ba4-590f-4e27-8206-01c4990df580');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "7E7uxYmwgRnI",
        "outputId": "dfe74056-77ee-498c-9dc6-21f196110538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72405, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "1d-oQ1lRWxTI",
        "outputId": "b6ee311f-6923-4eba-8e63-32f30289c8e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                   72405\n",
              "id                           72405\n",
              "author_id                    72405\n",
              "text                         72405\n",
              "retweets                     72405\n",
              "permalink                    72405\n",
              "date                         72405\n",
              "formatted_date               72405\n",
              "favorites                    72405\n",
              "mentions                     27554\n",
              "hashtags                     72402\n",
              "geo                              0\n",
              "urls                         33349\n",
              "search_hashtags              72405\n",
              "location                     72405\n",
              "text_clean                   72405\n",
              "tb_sentiment_polarity        72405\n",
              "tb_sentiment_subjectivity    72405\n",
              "textBlob_sentiment           72405\n",
              "vader_compound               72405\n",
              "vader_pos                    72405\n",
              "vader_neg                    72405\n",
              "vader_neu                    72405\n",
              "V_Sentiment                  72405\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación de data"
      ],
      "metadata": {
        "id": "s4qk4geXhaoc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos funcion para optimizar incluyendo stem y Lematización"
      ],
      "metadata": {
        "id": "IfTk9Rsmhnx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def textprep(line):\n",
        "    tokens = nltk.word_tokenize(str(line))\n",
        "    tokens = [w.lower() for w in tokens if len(w)>1]\n",
        "    tokens = [re.sub(r'[^A-Za-z0-9]+','',w) for w in tokens]\n",
        "    tokens = [w for w in tokens if w not in stop_words_nltk] \n",
        "    tokens= [wordnet_lemmatizer.lemmatize(w) for w in tokens]\n",
        "    tokens= [lancaster.stem(w) for w in tokens]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "6Ei3T9xuhmly"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtramos solo la columna de interés\n",
        "text_df = df[['text']]\n",
        "text_df.head()"
      ],
      "metadata": {
        "id": "ciaHgLYFvKMk",
        "outputId": "8cd130c2-c506-475d-8356-1e6406201cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  2020 is the year we #votethemout, the year we ...\n",
              "1  Winter has not stopped this group of dedicated...\n",
              "2  WEEK 55 of #ClimateStrike at the @UN. Next wee...\n",
              "3   A year of resistance, as youth protests shape...\n",
              "4   HAPPY HOLIDAYS #greta #gretathunberg #climate..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-939d45a5-4ae4-4da1-954e-f1a17c61c73c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020 is the year we #votethemout, the year we ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Winter has not stopped this group of dedicated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WEEK 55 of #ClimateStrike at the @UN. Next wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A year of resistance, as youth protests shape...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAPPY HOLIDAYS #greta #gretathunberg #climate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-939d45a5-4ae4-4da1-954e-f1a17c61c73c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-939d45a5-4ae4-4da1-954e-f1a17c61c73c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-939d45a5-4ae4-4da1-954e-f1a17c61c73c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creación de columna con tokenización de la columna de interés especifica\n",
        "text_df['tokens_twitter'] = text_df.apply(lambda row: textprep(row['text']), axis=1)\n",
        "text_df.head()"
      ],
      "metadata": {
        "id": "C_m8M7mInA5m",
        "outputId": "0433caf6-6c31-4b76-b822-23d13916ea53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  2020 is the year we #votethemout, the year we ...   \n",
              "1  Winter has not stopped this group of dedicated...   \n",
              "2  WEEK 55 of #ClimateStrike at the @UN. Next wee...   \n",
              "3   A year of resistance, as youth protests shape...   \n",
              "4   HAPPY HOLIDAYS #greta #gretathunberg #climate...   \n",
              "\n",
              "                                      tokens_twitter  \n",
              "0  [2020, year, votethemout, year, climatestrik, ...  \n",
              "1  [wint, stop, group, ded, clim, act, exampl, fo...  \n",
              "2  [week, 55, climatestrik, un, next, week, frida...  \n",
              "3  [year, resist, you, protest, shap, clim, chang...  \n",
              "4  [happy, holiday, gret, gretathunberg, climatec...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a6ca4c2-6334-45d9-98e8-44f05e4f8a17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tokens_twitter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020 is the year we #votethemout, the year we ...</td>\n",
              "      <td>[2020, year, votethemout, year, climatestrik, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Winter has not stopped this group of dedicated...</td>\n",
              "      <td>[wint, stop, group, ded, clim, act, exampl, fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WEEK 55 of #ClimateStrike at the @UN. Next wee...</td>\n",
              "      <td>[week, 55, climatestrik, un, next, week, frida...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A year of resistance, as youth protests shape...</td>\n",
              "      <td>[year, resist, you, protest, shap, clim, chang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAPPY HOLIDAYS #greta #gretathunberg #climate...</td>\n",
              "      <td>[happy, holiday, gret, gretathunberg, climatec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a6ca4c2-6334-45d9-98e8-44f05e4f8a17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a6ca4c2-6334-45d9-98e8-44f05e4f8a17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a6ca4c2-6334-45d9-98e8-44f05e4f8a17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Características y representación"
      ],
      "metadata": {
        "id": "Cz8uJi1B5HKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir el BoW (diccionario) de términos"
      ],
      "metadata": {
        "id": "TvcQLLrjgm2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_df['tokens_twitter'])"
      ],
      "metadata": {
        "id": "JGREnFOFFnLg",
        "outputId": "3e578671-fa2c-4784-da6a-c4eb266da5da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72405"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación del BoW - en gensim es Dictionary\n",
        "from gensim.corpora import Dictionary\n",
        "dictionary = Dictionary(text_df.tokens_twitter)"
      ],
      "metadata": {
        "id": "jXPGQCXuwXqc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-words representacion de documentos.\n",
        "corpus = [dictionary.doc2bow(line) for line in text_df.tokens_twitter]"
      ],
      "metadata": {
        "id": "YkyqTx6QHEcz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus[:10]:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "k4_hD_TLHcEX",
        "outputId": "4dc64118-de03-4133-c5e9-c176e833af41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 4)]\n",
            "[(2, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)]\n",
            "[(0, 1), (2, 1), (6, 1), (15, 1), (16, 1), (17, 1), (24, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2)]\n",
            "[(0, 1), (2, 1), (15, 1), (16, 1), (17, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2)]\n",
            "[(2, 1), (17, 1), (49, 1), (51, 1), (52, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (63, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1)]\n",
            "[(2, 1), (17, 2), (36, 1), (50, 1), (52, 1), (54, 1), (56, 1), (57, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1)]\n",
            "[(2, 1), (5, 1), (54, 1), (56, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1)]\n",
            "[(2, 1), (102, 1), (103, 1)]\n",
            "[(2, 1), (5, 1), (15, 1), (45, 1), (55, 1), (93, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1)]\n",
            "[(2, 1), (45, 1), (48, 1), (52, 1), (80, 1), (100, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir matriz de documentos vs términos"
      ],
      "metadata": {
        "id": "a3Goa699gzT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libreria para paralelizar\n",
        "import multiprocessing as mp\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "doc_term_matrix = pool.map(dictionary.doc2bow, [sentence for sentence in text_df.tokens_twitter])\n",
        "pool.close()\n"
      ],
      "metadata": {
        "id": "cSwWU75Gg0fi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in doc_term_matrix[:5]:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "2MN7GI4Hl2Bg",
        "outputId": "a2342bb8-5771-4f7f-ddbd-a927975d27f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 2), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 4)]\n",
            "[(2, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)]\n",
            "[(0, 1), (2, 1), (6, 1), (15, 1), (16, 1), (17, 1), (24, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2)]\n",
            "[(0, 1), (2, 1), (15, 1), (16, 1), (17, 2), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2)]\n",
            "[(2, 1), (17, 1), (49, 1), (51, 1), (52, 1), (54, 1), (55, 1), (56, 1), (57, 2), (58, 1), (59, 1), (63, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir modelo LDA"
      ],
      "metadata": {
        "id": "rx4ZCidLlTu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "\n",
        "t0 = time.time()\n",
        "lda_model = LdaMulticore(doc_term_matrix, num_topics=20, id2word = dictionary, passes=10, workers=10)\n",
        "print(time.time()-t0)"
      ],
      "metadata": {
        "id": "QI3baWDulUdC",
        "outputId": "72871207-0ad4-4c81-b312-56fd813ac649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process ForkPoolWorker-4:\n",
            "Process ForkPoolWorker-10:\n",
            "Process ForkPoolWorker-11:\n",
            "Process ForkPoolWorker-3:\n",
            "Process ForkPoolWorker-12:\n",
            "Process ForkPoolWorker-7:\n",
            "Process ForkPoolWorker-6:\n",
            "Traceback (most recent call last):\n",
            "KeyboardInterrupt\n",
            "Process ForkPoolWorker-8:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 346, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 719, in inference\n",
            "    Elogthetad = dirichlet_expectation(gammad)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 718, in inference\n",
            "    gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 723, in inference\n",
            "    meanchange = mean_absolute_difference(gammad, lastgamma)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 719, in inference\n",
            "    Elogthetad = dirichlet_expectation(gammad)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 718, in inference\n",
            "    gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 767, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"<__array_function__ internals>\", line 6, in dot\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 701, in inference\n",
            "    cts = np.fromiter((cnt for _, cnt in doc), dtype=self.dtype, count=len(doc))\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 719, in inference\n",
            "    Elogthetad = dirichlet_expectation(gammad)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 718, in inference\n",
            "    gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 701, in <genexpr>\n",
            "    cts = np.fromiter((cnt for _, cnt in doc), dtype=self.dtype, count=len(doc))\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"<__array_function__ internals>\", line 6, in dot\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "Process ForkPoolWorker-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 341, in worker_e_step\n",
            "    chunk_no, chunk, w_state = input_queue.get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5ccc8624915b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         )\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             self.add_lifecycle_event(\n\u001b[1;32m    522\u001b[0m                 \u001b[0;34m\"created\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_updates\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mupdateafter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training LDA model using %i processes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         logger.info(\n\u001b[1;32m    848\u001b[0m             \u001b[0;34m\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bound: at document #%i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m                 \u001b[0mgammad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# Initialize the variational distribution q(theta|gamma) for the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0mElogtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mexpElogtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def assigntopic(doc):\n",
        "    vector = lda_model[dictionary.doc2bow(doc)] \n",
        "    # opción 1: todos los tópicos ordenados de mayor a menor, podria ser topN tambien asi: return vector[:5] n=5\n",
        "    #vector = sorted(vector, key=lambda item: -item[1])\n",
        "    # opción 2: asignar el tópico mayor a cada documento\n",
        "    vector = max(vector,key=lambda item: item[1])\n",
        "    return vector"
      ],
      "metadata": {
        "id": "JkYbDMlvoH-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['topics'] = text_df.apply(lambda row: assigntopic(row['tokens_twitter']), axis=1)\n",
        "text_df.head()"
      ],
      "metadata": {
        "id": "S7CMmpqTqjK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LDA model\n",
        "lda_model2 = LdaMulticore(corpus=corpus,\n",
        "                                       id2word=dictionary,\n",
        "                                       num_topics=20)"
      ],
      "metadata": {
        "id": "OPAJ-9qmdk_6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model2.print_topics())\n",
        "doc_lda = lda_model2[corpus]"
      ],
      "metadata": {
        "id": "LGpBAgGZgMol",
        "outputId": "a4f60e7a-2a74-4c06-cf0b-81e6ec526fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.026*\"climatestrik\" + 0.025*\"stat\" + 0.025*\"climateact\" + '\n",
            "  '0.015*\"climatecris\" + 0.014*\"capitol\" + 0.013*\"get\" + 0.010*\"mak\" + '\n",
            "  '0.010*\"stil\" + 0.010*\"unit\" + 0.010*\"thank\"'),\n",
            " (1,\n",
            "  '0.030*\"er\" + 0.017*\"climatechang\" + 0.014*\"amp\" + 0.014*\"energy\" + '\n",
            "  '0.012*\"nee\" + 0.011*\"keep\" + 0.011*\"term\" + 0.009*\"work\" + 0.009*\"wal\" + '\n",
            "  '0.008*\"cle\"'),\n",
            " (2,\n",
            "  '0.031*\"amp\" + 0.013*\"lead\" + 0.012*\"gen\" + 0.011*\"act\" + '\n",
            "  '0.011*\"climatechang\" + 0.011*\"thank\" + 0.010*\"hear\" + 0.010*\"today\" + '\n",
            "  '0.010*\"gre\" + 0.009*\"commit\"'),\n",
            " (3,\n",
            "  '0.064*\"climatechang\" + 0.031*\"bushfir\" + 0.025*\"climatecris\" + '\n",
            "  '0.022*\"globalwarm\" + 0.017*\"fir\" + 0.015*\"austral\" + '\n",
            "  '0.013*\"climatechangeisr\" + 0.012*\"climateemerg\" + 0.011*\"nt\" + '\n",
            "  '0.011*\"http\"'),\n",
            " (4,\n",
            "  '0.017*\"amp\" + 0.016*\"climatechang\" + 0.014*\"world\" + 0.012*\"in\" + '\n",
            "  '0.010*\"ind\" + 0.009*\"work\" + 0.009*\"warn\" + 0.009*\"cre\" + 0.008*\"driv\" + '\n",
            "  '0.008*\"fresh\"'),\n",
            " (5,\n",
            "  '0.538*\"\" + 0.012*\"http\" + 0.012*\"climatechang\" + 0.009*\"climatebreakdown\" + '\n",
            "  '0.008*\"ded\" + 0.006*\"climateact\" + 0.006*\"globalwarm\" + 0.006*\"espec\" + '\n",
            "  '0.005*\"allarecal\" + 0.005*\"stud\"'),\n",
            " (6,\n",
            "  '0.071*\"climatestrik\" + 0.026*\"today\" + 0.019*\"peopl\" + 0.014*\"capitol\" + '\n",
            "  '0.014*\"fridaysforfut\" + 0.014*\"young\" + 0.014*\"stud\" + 0.013*\"clim\" + '\n",
            "  '0.013*\"climateact\" + 0.011*\"climatechang\"'),\n",
            " (7,\n",
            "  '0.058*\"climatestrik\" + 0.043*\"climatechang\" + 0.037*\"gretathunberg\" + '\n",
            "  '0.037*\"fridaysforfut\" + 0.035*\"climateact\" + 0.025*\"climatecris\" + '\n",
            "  '0.022*\"sydney\" + 0.019*\"http\" + 0.019*\"planet\" + 0.018*\"climateemerg\"'),\n",
            " (8,\n",
            "  '0.129*\"greennewd\" + 0.024*\"aoc\" + 0.015*\"sunrisemvmt\" + 0.014*\"modern\" + '\n",
            "  '0.012*\"demdeb\" + 0.012*\"sen\" + 0.011*\"candid\" + 0.010*\"medicareforal\" + '\n",
            "  '0.009*\"pas\" + 0.009*\"berniesand\"'),\n",
            " (9,\n",
            "  '0.025*\"greenpeac\" + 0.021*\"globalgo\" + 0.017*\"climatechang\" + 0.014*\"http\" '\n",
            "  '+ 0.014*\"jersey\" + 0.014*\"globalwarm\" + 0.014*\"sum\" + 0.014*\"gop\" + '\n",
            "  '0.012*\"eq\" + 0.012*\"holiday\"'),\n",
            " (10,\n",
            "  '0.037*\"amp\" + 0.017*\"climatechang\" + 0.013*\"reduc\" + 0.012*\"farm\" + '\n",
            "  '0.012*\"sustain\" + 0.011*\"http\" + 0.009*\"environ\" + 0.009*\"consum\" + '\n",
            "  '0.009*\"le\" + 0.008*\"pour\"'),\n",
            " (11,\n",
            "  '0.032*\"climatechang\" + 0.011*\"nt\" + 0.010*\"lik\" + 0.010*\"talk\" + '\n",
            "  '0.009*\"car\" + 0.009*\"nee\" + 0.009*\"get\" + 0.009*\"firedrillfriday\" + '\n",
            "  '0.008*\"real\" + 0.008*\"polit\"'),\n",
            " (12,\n",
            "  '0.054*\"new\" + 0.029*\"year\" + 0.028*\"http\" + 0.016*\"climatechang\" + '\n",
            "  '0.015*\"deal\" + 0.014*\"green\" + 0.014*\"landscapearchitect\" + 0.013*\"design\" '\n",
            "  '+ 0.011*\"school\" + 0.011*\"sustain\"'),\n",
            " (13,\n",
            "  '0.138*\"sustain\" + 0.049*\"http\" + 0.035*\"amp\" + 0.026*\"environ\" + '\n",
            "  '0.025*\"savetheplanet\" + 0.019*\"recyc\" + 0.017*\"utmsourceigtwittersh\" + '\n",
            "  '0.013*\"green\" + 0.011*\"day\" + 0.010*\"nat\"'),\n",
            " (14,\n",
            "  '0.033*\"auspol\" + 0.020*\"look\" + 0.020*\"http\" + 0.018*\"globalwarm\" + '\n",
            "  '0.017*\"climatechang\" + 0.012*\"glob\" + 0.011*\"warm\" + 0.011*\"minim\" + '\n",
            "  '0.011*\"blog\" + 0.010*\"lik\"'),\n",
            " (15,\n",
            "  '0.061*\"clim\" + 0.049*\"chang\" + 0.038*\"climatechang\" + 0.021*\"act\" + '\n",
            "  '0.015*\"nee\" + 0.014*\"climateact\" + 0.013*\"sci\" + 0.012*\"actonclim\" + '\n",
            "  '0.010*\"issu\" + 0.010*\"climatecris\"'),\n",
            " (16,\n",
            "  '0.058*\"clim\" + 0.033*\"dc\" + 0.031*\"climatestrik\" + 0.031*\"act\" + '\n",
            "  '0.026*\"join\" + 0.020*\"u\" + 0.019*\"http\" + 0.019*\"glob\" + 0.018*\"strike\" + '\n",
            "  '0.018*\"washington\"'),\n",
            " (17,\n",
            "  '0.020*\"climatechang\" + 0.013*\"environ\" + 0.013*\"savetheplanet\" + 0.011*\"oc\" '\n",
            "  '+ 0.011*\"us\" + 0.011*\"http\" + 0.009*\"on\" + 0.008*\"tre\" + 0.007*\"lik\" + '\n",
            "  '0.007*\"pleas\"'),\n",
            " (18,\n",
            "  '0.085*\"de\" + 0.055*\"la\" + 0.047*\"par\" + 0.044*\"le\" + 0.037*\"en\" + '\n",
            "  '0.032*\"un\" + 0.025*\"climatestrik\" + 0.020*\"el\" + 0.018*\"climateact\" + '\n",
            "  '0.018*\"est\"'),\n",
            " (19,\n",
            "  '0.033*\"environ\" + 0.028*\"wat\" + 0.027*\"climatechang\" + 0.021*\"http\" + '\n",
            "  '0.016*\"savetheplanet\" + 0.015*\"amp\" + 0.013*\"air\" + 0.012*\"heal\" + '\n",
            "  '0.012*\"cle\" + 0.009*\"excel\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing LDA model results"
      ],
      "metadata": {
        "id": "taOKE5Hrgqoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyLDAvis \n",
        "import gensim\n",
        "import pickle \n",
        "import pyLDAvis"
      ],
      "metadata": {
        "id": "Hbz-aB1xga6Q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim.prepare as prepare"
      ],
      "metadata": {
        "id": "XUD3i7MRkSpr",
        "outputId": "ab009000-220d-4f8e-9ea6-f6675e7e8588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-100c88315abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis.gensim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "#LDAvis_data_filepath = os.path.join(')\n",
        "# # this is a bit time consuming - make the if statement True\n",
        "# # if you want to execute visualization prep yourself\n",
        "if 1 == 1:\n",
        "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model2, corpus, dictionary)\n",
        "    with open(\"/content/cloned-repo/Trabajo3/out\", 'wb') as f:\n",
        "        pickle.dump(LDAvis_prepared, f)\n",
        "# load the pre-prepared pyLDAvis data from disk\n",
        "with open(\"/content/cloned-repo/Trabajo3/out\", 'rb') as f:\n",
        "    LDAvis_prepared = pickle.load(f)\n",
        "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_20topics.html')\n",
        "LDAvis_prepared"
      ],
      "metadata": {
        "id": "Sc6V_UzAgu3n",
        "outputId": "f21069d7-f9a2-4233-8050-4442766f7b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a757468c550c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# # if you want to execute visualization prep yourself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mLDAvis_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/cloned-repo/Trabajo3/out\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLDAvis_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pyLDAvis' has no attribute 'gensim'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis frecuencial por token o hashtags"
      ],
      "metadata": {
        "id": "Ypx9bBK_5LnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nubes de palabras por token o hashtags"
      ],
      "metadata": {
        "id": "6LWz9PDA5T7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis exploratorio no supervisado utilizando técnicas de LDA"
      ],
      "metadata": {
        "id": "yMe5YdkZ5h-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación y análisis de sentimientos"
      ],
      "metadata": {
        "id": "0BO2mYq55pvG"
      }
    }
  ]
}